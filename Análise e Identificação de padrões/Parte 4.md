# ğŸš€ Parte 4 â€” NormalizaÃ§Ã£o de Oportunidades (n-gramas â†’ lacunas temÃ¡ticas)

## ğŸ“Œ Objetivo

Consolidar **padrÃµes raros-fortes de n-gramas** extraÃ­dos dos **tÃ­tulos da prÃ³pria base** em **lacunas temÃ¡ticas acionÃ¡veis**, com contexto, mÃ©tricas e **ranking por score estimado**.
O resultado final Ã© gravado em **IDentificaÃ§Ã£o de padrÃµes** (linha **2**), coluna **Lacunas**.

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

```
Google Sheets Trigger (a cada 1 min)
â†’ Aggregate6 (pass-through)
â†’ Get row(s) in sheet6 (Dados ordenados)
â†’ Edit Fields8 (row_number, Titulo, outlierScore)
â†’ Code in JavaScript7 (extrai n-gramas raros-fortes e benchmarks da base)
â†’ Aggregate7 (aggregateAllItemData)
â†’ AI Agent6 (normaliza em lacunas temÃ¡ticas)  [modelo: gpt-4o-mini]
â†’ Update row in sheet5 (IDentificaÃ§Ã£o de padrÃµes!Lacunas = output; row_number = 2)
```

---

## ğŸ“¦ NÃ³s do Workflow (o que de fato acontece)

### 1) **Google Sheets Trigger**

**Tipo:** `googleSheetsTrigger` â€¢ **FrequÃªncia:** `everyMinute`
**Documento:** *Teste Dev IA Pleno* (`1XlZT...RV1WkQ`)
**Aba:** **Dados ordenados** (`gid=304295346`)
Dispara a leitura da base e envia o lote adiante.

---

### 2) **Aggregate6**

**Tipo:** `aggregate`
FunÃ§Ã£o: apenas encaminha os itens do gatilho para leitura.

---

### 3) **Get row(s) in sheet6** (Read)

**Tipo:** `googleSheets`
LÃª as linhas de **Dados ordenados** (tÃ­tulos + mÃ©tricas).

---

### 4) **Edit Fields8** (normalizaÃ§Ã£o de campos)

**Tipo:** `set`
Cria/garante:

* `row_number` = `{{$json.row_number}}` (number)
* `Titulo` = `{{$json["Titulo "]}}` (string)
* `outlierScore` = `{{$json.outlierScore}}` (string)

> **Obs.:** `outlierScore` vem como *string* aqui, mas o prÃ³ximo nÃ³ converte para **Number**.

---

### 5) **Code in JavaScript7** â€” *ExtraÃ§Ã£o de n-gramas raros-fortes*

**Tipo:** `code` (JS)
**Entrada:** lote de itens com `Titulo` (ou â€œTitulo â€) e `outlierScore`.
**SaÃ­da:** objeto JSON com:

* `resumo`: `{ totalVideosBase, topConsiderados, p50, p75, p90, criterios {...} }`
* `padroesRarosFortes`: lista de n-gramas raros e fortes com mÃ©tricas

**O que o script faz (fiel ao cÃ³digo):**

* **Normaliza** tÃ­tulos (lowercase, remove acentos, corta *sufixos* de canal/autor apÃ³s separadores: `" | "`, `" - "`, `"â€”"`, `"â€“"`, etc.).
* **Tokeniza** removendo *stopwords* PT/EN e ruÃ­dos.
* **Ã‚ncoras de domÃ­nio**: mantÃ©m apenas n-gramas que contenham termos do nicho (ex.: `leg, weak, stairs, vitamin, perna, fortalecer...`).
* **RuÃ­do/cauda**: filtra tokens de *noise* frequentes (ex.: `dr, motivation, channel, best ...`).
* **Gera n-gramas** de tamanho `2` e `3` (bigramas/trigramas).
* **Benchmarks prÃ³prios**: calcula `p50`, `p75`, `p90` do `outlierScore` da **prÃ³pria base**.
* **Top da base**: define `topK = min(round(total * 0.10), 50)` e marca presenÃ§a nos TOPs.
* **Raridade**: mantÃ©m apenas `RARE_MIN â‰¤ ocorrÃªncias â‰¤ RARE_MAX` (2 a 6, no cÃ³digo).
* **ForÃ§a**: exige **â‰¥ p75** de `outlierScoreMedio` (prioriza **p90+**).
* **PresenÃ§a em TOPs**: quando `REQUIRE_TOP_HIT = true`, exige aparecer **â‰¥1x em TOP**.
* **Ranking**: ordena por banda (`p90+` > `p75+`), depois `outlierScoreMedio`, depois *mais raro* (menor `count`) e, por fim, presenÃ§a nos TOPs.
* **Score estimado** (60â€“95): combina raridade, forÃ§a (banda) e *top boost*.
* **Retorno**: atÃ© **20** padrÃµes (`RETURN_LIMIT = 20`), **sempre com exemplos reais** (tÃ­tulos).

> **Importante:** aqui **nÃ£o hÃ¡ corte fixo de 50 linhas de entrada**. O script processa *toda a base lida* e sÃ³ limita **`topK`** (para marcar presenÃ§a em TOP) e o **nÃºmero de padrÃµes retornados** (20).

---

### 6) **Aggregate7**

**Tipo:** `aggregate` â€¢ **Config:** `aggregateAllItemData`
Agrupa a saÃ­da do script anterior em um Ãºnico item.

> **Estrutura esperada no prÃ³ximo nÃ³:** o **AI Agent6** lÃª `{{$json.data}}`. Com `aggregateAllItemData`, o campo resultante costuma ser `data` contendo os payloads anteriores.
> **Se seu ambiente retornar o objeto direto (sem `data`)**, ajuste o parÃ¢metro `text` do **AI Agent6** para `={{ $json }}` ou mude o modo de agregaÃ§Ã£o para garantir `data`.

---

### 7) **AI Agent6** â€” *Normalizador de Oportunidades*

**Tipo:** `@n8n/n8n-nodes-langchain.agent`
**Modelo:** `gpt-4o-mini` (via **OpenAI Chat Model6**)
**Entrada (text):** `={{ $json.data }}` â†’ deve conter `{ resumo, padroesRarosFortes }` do passo anterior.
**FunÃ§Ã£o:** agrupar n-gramas semelhantes, consolidar mÃ©tricas por **tema**, calcular **concorrÃªncia** e **scoreEstimado**, e devolver **atÃ© 10 lacunas** ordenadas.

ğŸ“ **Prompt (preencher manualmente):**

```
<role> VocÃª Ã© um **Normalizador de Oportunidades**. Seu papel Ã© transformar padrÃµes de n-gramas detectados automaticamente em **lacunas temÃ¡ticas consolidadas** â€” agrupadas, contextualizadas e pontuadas â€” para o agente gerador de ideias. </role>
<input> VocÃª receberÃ¡ um objeto JSON com duas partes:
{
  "resumo": {
    "totalVideosBase": number,
    "p75": number,
    "p90": number
  },
  "padroesRarosFortes": [
    {
      "ngrama": "string",
      "ocorrencias": number,
      "presentesNosTop": number,
      "outlierScoreMedio": number,
      "exemplos": ["string", "string", "string"]
    }
  ]
}


Esses dados vÃªm do analisador de benchmark e representam padrÃµes reais observados em vÃ­deos de um mesmo subnicho (ex: weak legs).
Os n-gramas podem conter combinaÃ§Ãµes de termos em inglÃªs ou portuguÃªs, e jÃ¡ foram filtrados por relevÃ¢ncia.
</input>

<task>

Sua tarefa Ã© consolidar esses n-gramas em temas acionÃ¡veis, extraindo o contexto e produzindo uma lista de lacunas temÃ¡ticas de alto potencial.

Etapas:

Agrupar n-gramas semelhantes:

Use a semelhanÃ§a semÃ¢ntica ou tokens-chave para unir expressÃµes relacionadas.

Exemplo:

â€œvitamin comboâ€, â€œlegs vitaminâ€ â†’ â€œvitaminas que fortalecem pernas fracasâ€

â€œclimb stairsâ€, â€œstairs easilyâ€ â†’ â€œsubir escadas com facilidadeâ€

Calcular mÃ©tricas consolidadas:

videosExistentes: soma das ocorrÃªncias.

percentualDaBase: (videosExistentes / totalVideosBase) Ã— 100.

outlierScoreMedio: mÃ©dia ponderada das pontuaÃ§Ãµes do grupo.

concorrencia:

< 2% â†’ â€œbaixaâ€

2â€“5% â†’ â€œmediaâ€

5% â†’ â€œaltaâ€

exemplos: atÃ© 3 tÃ­tulos reais mais representativos.

Pontuar e ranquear:

Base = 50

+25 se outlierScoreMedio >= p90

+15 se outlierScoreMedio >= p75

+15 se percentualDaBase < 2

+10 se percentualDaBase < 5

Score final limitado entre 60 e 95.

Produzir 10 lacunas principais:

Ordenadas por scoreEstimado (descendente).

Usar nomes de tema claros e compreensÃ­veis.

NÃ£o inventar termos nÃ£o presentes nos dados.

Traduzir tÃ­tulos ou termos para portuguÃªs quando fizer sentido.

</task>

<output_format>

{
  "nicho": "weak legs / idosos",
  "data_analise": "YYYY-MM-DD",
  "benchmarks": { "p75": number, "p90": number },
  "baseAnalisada": number,
  "lacunas": [
    {
      "ranking": number,
      "tema": "string",
      "videosExistentes": number,
      "percentualDaBase": number,
      "outlierScoreMedio": number,
      "concorrencia": "baixa|media|alta",
      "exemplos": ["string", "string", "string"],
      "scoreEstimado": number
    }
  ]
}


</output_format>

<regras_criticas>
âœ… Use apenas dados fornecidos â€” nÃ£o crie informaÃ§Ãµes externas.
âœ… Mantenha nomes de tema curtos e prÃ¡ticos.
âœ… Sempre retorne 10 lacunas no mÃ¡ximo.
âœ… Traduza termos tÃ©cnicos em linguagem natural (ex: â€œweak shaky legsâ€ â†’ â€œpernas fracas e trÃªmulasâ€).
âœ… Priorize temas que combinam alta performance (outlierScoreMedio) e baixa concorrÃªncia.
âŒ NÃ£o misture subnichos diferentes.
âŒ NÃ£o invente tÃ­tulos de vÃ­deo â€” use apenas exemplos reais.
</regras_criticas>
```

**Como o prompt limita o retorno (de acordo com as regras do seu projeto):**

* Exige **apenas dados fornecidos** (sem inventar).
* **Agrupa** por semelhanÃ§a/termos-chave e **calcula mÃ©tricas** (videosExistentes, percentualDaBase, outlierScoreMedio, concorrencia).
* **Pontua** e **ranqueia** (base 50 + bÃ´nus por p90/p75 + baixa concorrÃªncia, clamp 60â€“95).
* **Retorna no formato JSON** do *output_format* (mÃ¡x. 10 lacunas).
* **Traduz termos tÃ©cnicos** para portuguÃªs quando fizer sentido.

> **AtenÃ§Ã£o:** Como o `text` estÃ¡ `={{ $json.data }}`, garanta que o **Aggregate7** realmente produza a chave `data` contendo `{resumo, padroesRarosFortes}`. Se nÃ£o existir, ajuste (`={{ $json }}`) para evitar payload vazio.

---

### 8) **OpenAI Chat Model6**

**Tipo:** `@n8n/n8n-nodes-langchain.lmChatOpenAi`
**Modelo:** `gpt-4o-mini` â€¢ **Credenciais:** *OpenAI API (Guilherme)*
Fornece o LLM ao **AI Agent6**.

---

### 9) **Update row in sheet5** (Write)

**Tipo:** `googleSheets` (operation: `update`)
**Destino:** **IDentificaÃ§Ã£o de padrÃµes** (`gid=1109606750`)
**Match:** `row_number = 2`
**Mapeamento:**

* `Lacunas` = `={{ $json.output }}`  â† **JSON final das lacunas**
* `row_number` = `2`

---

## ğŸ§ª O que Ã© verificado / limitado

* **TOP vs base:** o script calcula `topK = min(round(total*10%), 50)` **apenas para marcar presenÃ§a nos TOPs**, nÃ£o para limitar a base lida.
* **Raridade:** n-gramas com **2â€“6** ocorrÃªncias.
* **ForÃ§a:** **â‰¥ p75** (prioriza **p90+** pelo `outlierScoreMedio`).
* **Ã‚ncora de domÃ­nio + sem ruÃ­do:** sÃ³ entra n-grama com **termos do nicho** e **sem tokens de ruÃ­do**.
* **SaÃ­da do script:** **atÃ© 20** padrÃµes; cada padrÃ£o traz **exemplos reais** (mÃ¡x. 3 tÃ­tulos).
* **SaÃ­da final (AI):** **atÃ© 10 lacunas** no JSON padronizado.
* **PersistÃªncia:** grava em **IDentificaÃ§Ã£o de padrÃµes â†’ linha 2 â†’ coluna Lacunas**.

---

## ğŸ—‚ï¸ Planilhas envolvidas

* **Dados ordenados** (`gid=304295346`) â€” **origem** dos tÃ­tulos/outlierScore.
* **IDentificaÃ§Ã£o de padrÃµes** (`gid=1109606750`) â€” **destino** do JSON final de **Lacunas** (linha **2**).

---

## âš ï¸ ObservaÃ§Ãµes importantes (do jeito que estÃ¡ no cÃ³digo)

1. **`outlierScore` como string em `Edit Fields8`**: o JS converte para nÃºmero; estÃ¡ ok, mas vale padronizar a coluna na planilha para nÃºmero (evita â€œNaNâ€ silencioso).
2. **`Aggregate7 â†’ AI Agent6 (text = {{$json.data}})`**: confirme que a saÃ­da do *aggregate* expÃµe `data`. Se nÃ£o, ajuste o *binding* (ou o modo de agregaÃ§Ã£o) para nÃ£o quebrar o prompt.
3. **NÃ£o hÃ¡ corte fixo a 50 entradas** nesta parte (diferente das Partes 2/3). O limite de â€œ50â€ aparece **apenas** no cÃ¡lculo de `topK`. Se quiser uniformizar, adicione um `Code` antes do JS para `slice(0, 50)`.

---

## âœ… Resultado

A partir da prÃ³pria base, a automaÃ§Ã£o **extrai n-gramas raros-fortes**, calcula **benchmarks internos** (p75/p90) e **marca presenÃ§a em TOPs**; em seguida, o agente **normaliza** em **lacunas temÃ¡ticas** (mÃ¡x. 10) com **score estimado** e **exemplos reais**, gravando o JSON final em **IDentificaÃ§Ã£o de padrÃµes â†’ linha 2 â†’ Lacunas**.
